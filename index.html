<!doctype html>
<html>
	<head>
		<meta charset="utf-8">
		<meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=no">

		<title>End-to-end music demixing with pytorch</title>

		<link rel="stylesheet" href="css/reveal.css">
		<link rel="stylesheet" href="css/theme/lirmm.css">
 		<link href="fontawesome-free-5.3.1-web/css/all.css" rel="stylesheet">
		<!-- <link rel="stylesheet" href="https://use.fontawesome.com/releases/v5.1.0/css/all.css" integrity="sha384-lKuwvrZot6UHsBSfcMvOkWwlCMgc0TaWr+30HWe3a4ltaBwTZhyTEggF5tJv8tbt" crossorigin="anonymous"> -->

		<!-- Theme used for syntax highlighting of code -->
		<link rel="stylesheet" href="lib/css/github.css">

		<!-- Printing and PDF exports -->
		<script>
			var link = document.createElement( 'link' );
			link.rel = 'stylesheet';
			link.type = 'text/css';
			link.href = window.location.search.match( /print-pdf/gi ) ? 'css/print/pdf.css' : 'css/print/paper.css';
			document.getElementsByTagName( 'head' )[0].appendChild( link );
		</script>
	</head>
	<body>
		<div class="reveal">
			<div class="slides">

				<section id="cover" data-background="css/theme/img/background-red.jpg" data-background-repeat="no-repeat" data-background-size="cover" data-background-position="0 0" data-state="no-title-footer no-progressbar has-dark-background">
					<h2 id="covertitle">End-to-end music demixing with pytorch</h2>
					<p id="coverauthors">
						Antoine Liutkus & Fabian-Robert Stöter<br/>
						Inria and LIRMM, Montpellier<br/>
						<p>
							antoine.liutkus@inria.fr<br />
						</p>
						<p>
							fabian-robert.stoter@inria.fr<br />
							<i class="fab fa-twitter"></i>faroit
						</p>

					</p>
					<p>
					September 16th, 2019
					</p>
					<p>
					<img src="css/theme/img/inria-cover.svg" id="inria" class="logo" alt="">
				</section>


<!-- Introduction

In an introductory section, we will motivate the tutorial by explaining how music separation with DNN emerged with
data-driven methods coming from machine-learning or image processing communities. This comes with machine-learning
tricks to make methods work in practice. Meanwhile, many audio processing good practices are often forgotten or not
correctly applied, although they are mandatory for good performance.
• Timeline for DNN music separation
A brief history of the topic in the bigger picture: machine learning on the one hand, source separation on the other
hand.
• Outline
The baseline system: what is the state of the art? Quick literature review
How to implement and make it work? The distinction between training and testing.
An audio demo of the critical impact of engineering for the “same” system.

-->

<!-- INTRODUCTION -->
<section>
	<h1>Music Unmixing/Separation</h1>
	<img width="45%" style="float:left" src="assets/intro1.png" alt="">
	<img class="fragment" width="45%" src="assets/intro2.png" alt="">
</section>

<section>
	<h1>Applications</h1>
	<img width="60%" style="float:right" src="assets/karaoke.jpg" alt="">

	<ul>
		<li>Automatic Karaoke</li>
		<li>Creative Music Production</li>
		<li>Active listening</li>
		<li>Upmixing (stereo $\Rightarrow$ 5.1)</li>
		<li>Music Education</li>
		<li>Pre-processing for MIR</li>
	</ul>
</section>

<section>
	<h1>Time frequency representations</h1>
	<img width="100%" style="margin-top:5%; float:left" src="assets/STFT.svg" alt="">
</section>

<section data-background-transition="none" data-state="no-title-footer"  data-background-image="assets/demotrack/mix.jpg">
	<!-- <h1><button data-audio="assets/demotrack/mixture.m4a">▶</button></h1> -->
	<h1 style="margin-top:5%; color:white">Mixture spectrogram</h1>
</section>
<section data-background-transition="none">
	<section data-background-transition="none" data-state="no-title-footer"  data-background-image="assets/demotrack/vocals.jpg">
		<!-- <h1><button data-audio="assets/demotrack/vocals.m4a">▶</button></h1> -->
		<h1 style="margin-top:5%; color:white">Vocals spectrogram</h1>
	</section>
	<section data-background-transition="none" data-state="no-title-footer"  data-background-image="assets/demotrack/drums.jpg">
		<!-- <h1><button data-audio="assets/demotrack/drums.m4a">▶</button></h1> -->
		<h1 style="margin-top:5%; color:white">Drums spectrogram</h1>
	</section>
	<section data-background-transition="none" data-state="no-title-footer"  data-background-image="assets/demotrack/bass.jpg">
		<!-- <h1><button data-audio="assets/demotrack/bass.m4a">▶</button></h1> -->
		<h1 style="margin-top:5%; color:white">Bass spectrogram</h1>
	</section>
</section>

<section>
	<h1>The pytorch <code>Open-unmix</code> (UMX) model</h1>
	<img  style="margin-top:2%; float:left" width="160%" src="assets/UMX1.svg" alt="">
</section>
<section>
	<h1>The pytorch <code>Open-unmix</code> (UMX) model</h1>
	<img  style="margin-top:2%; float:left" width="160%" src="assets/UMX2.svg" alt="">
</section>
<section>
	<h1>The pytorch <code>Open-unmix</code> (UMX) model</h1>
	<img  style="margin-top:2%; float:left" width="160%" src="assets/UMX.svg" alt="">
</section>
<section>
	<h1>The pytorch <code>Open-unmix</code> (UMX) model</h1>
	<img  style="margin-top:2%;" width="100%" src="assets/UMX1.svg" alt="">
		<h2>A state of the art system</h2>
		<ul>
			<li>MIT-licensed Pytorch implementation</li>
			<li><a href=https://github.com/sigsep/open-unmix-pytorch><i class="fab fa-github"></i>/sigsep/open-unmix-pytorch</a>  6.3 dB vocals SDR!</li>
		</ul>
		<h6 style="margin-top:4%;color:gray">
			F. Stöter et al, "Open-Unmix - A reference implementation for audio source separation", JOSS 2019.
		</h6>

</section>

<section>
	<h1>What <code>open-unmix</code> can achieve</h1>
	<iframe src='http://umx-sisec18.s3-website.eu-west-3.amazonaws.com/' style='height:500px;width:100%'></iframe>
</section>

<section>
	<h1>Open-unmix: <code>master</code> branch</h1>
	<img  style="margin-top:2%; float:left" width="160%" src="assets/open-unmix-master_branch1.svg" alt="">
</section>
<section>
	<h1>Open-unmix: <code>master</code> branch</h1>
	<img  style="margin-top:2%; float:left" width="160%" src="assets/open-unmix-master_branch2.svg" alt="">
</section>
<section>
	<h1>Open-unmix: <code>master</code> branch</h1>
	<img  style="margin-top:2%; float:left" width="160%" src="assets/open-unmix-master_branch3.svg" alt="">
</section>
<section>
	<h1>Open-unmix: <code>master</code> branch</h1>
	<img  style="margin-top:2%; float:left" width="160%" src="assets/open-unmix-master_branch4.svg" alt="">
</section>
<section>
	<h1>Open-unmix: <code>master</code> branch</h1>
	<img  style="margin-top:2%; float:left" width="160%" src="assets/open-unmix-master_branch5.svg" alt="">
</section>


<section>
	<h1>Our submission to the hackaton!</h1>
	<h2>Open-unmix: <code>torchfilters</code></h2>
</section>
<section>
	<h1>Open-unmix: <code>master</code> branch</h1>
	<img  style="margin-top:2%; float:left" width="160%" src="assets/open-unmix-master_branch4.svg" alt="">
</section>
<section>
	<h1>Open-unmix: <code>torchfilters</code> branch</h1>
	<img  style="margin-top:2%; float:left" width="160%" src="assets/open-unmix-torchfilters_branch1.svg" alt="">
</section>
<section>
	<h1>Open-unmix: <code>torchfilters</code> branch</h1>
	<img  style="margin-top:2%; float:left" width="160%" src="assets/open-unmix-torchfilters_branch2.svg" alt="">
</section>
<section>
	<h1>Our submission to the hackaton!</h1>
	<h2>Open-unmix: <code>torchfilters</code></h2>
	<ul>
		<li>Stereo Wiener filtering in <code>torch</code></li>
		<li class='fragment'>inverse ISTFT with <code>torchaudio</code></li>
		<li  class='fragment'>End-to-end <code>Separator</code> torch.Module
			<img   class='fragment' style="margin-top:2%;" width="100%" src="assets/torchhub.png" alt="">
		</li>
		<li  class='fragment'>Computing time for 1mn audio
			<ul  class='fragment'>Before:
				<li>cpu: 31.3s</li>
				<li>cuda: 22.5s</li>
			</ul>
			<ul  class='fragment'> After
				<li>cpu: 23.4s <font color=red>(25% speedup)</font></li>
				<li>cuda: 6.8s <font color=red>(70% speedup)</font></li>
			</ul>
		</li>
	</ul>
</section>

			</div>
			<div class='footer'>
				<img src="css/theme/img/inria-bottom.svg" alt="Logo" />
				<div id="middlebox">End-to-end music demixing with pytorch</div>
			</div>
		</div>

		<script src="lib/js/head.min.js"></script>
		<script src="js/reveal.js"></script>

		<script>
			// More info about config & dependencies:
			// - https://github.com/hakimel/reveal.js#configuration
			// - https://github.com/hakimel/reveal.js#dependencies
			Reveal.initialize({
				controls: true,
				progress: false,
				history: true,
				center: false,
				slideNumber: true,
				minScale: 1,
				maxScale: 5,
				viewDistance: 30,
				transition: 'none', //

				dependencies: [
					{ src: 'plugin/markdown/marked.js' },
					{ src: 'plugin/markdown/markdown.js' },
					{ src: 'plugin/notes/notes.js', async: true },
					{ src: 'node_modules/reveald3/reveald3.js' },
					{ src: 'plugin/math-katex/math-katex.js', async: true },
					{ src: 'plugin/highlight/highlight.js', async: true, callback: function() { hljs.initHighlightingOnLoad(); } }
				]
			});
		</script>
	</body>
</html>
